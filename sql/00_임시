# =========================================================
# CELL 1. 환경/라이브러리 준비
# - 데이터 조회(getData), pandas 처리, S3 업로드(boto3), parquet 저장(pyarrow)
# =========================================================

from bigdataquery import getData
import pandas as pd
import numpy as np
import boto3
import io
import re
from datetime import datetime, timedelta, date

import pyarrow as pa
import pyarrow.parquet as pq

pd.set_option("display.max_columns", 200)
pd.set_option("display.width", 200)



# =========================================================
# CELL 2. 기본 파라미터 설정
# - 개발 단계에서는 기간을 짧게(10~30일)로 검증
# - 운영/1년치는 나중에 동일 코드로 확장 가능
# =========================================================

# 조회 기간 (Impala TIMESTAMP 기반)
END_DATE = date.today() - timedelta(days=1)          # 어제
START_DATE = END_DATE - timedelta(days=30)          # 최근 30일 (검증용)
# START_DATE = END_DATE - timedelta(days=365)       # 1년치로 갈 때

# 특정 RS 레시피만 보고 싶으면 넣기 (없으면 None)
ONLY_PPID = None
# ONLY_PPID = "TT_RA-108030"

print("START_DATE:", START_DATE, "END_DATE:", END_DATE, "ONLY_PPID:", ONLY_PPID)




# =========================================================
# CELL 3. S3 접속 설정 (endpoint 포함)
# - 회사 환경에서는 endpoint_url이 필수인 경우가 많음
# - 아래 값은 사용자 환경에 맞게 채우세요
# =========================================================

S3_ENDPOINT_URL = "https://YOUR_S3_ENDPOINT"   # 예: https://s3.company.com
S3_REGION = "ap-northeast-2"                   # 보통 서울
S3_ACCESS_KEY = "YOUR_ACCESS_KEY"
S3_SECRET_KEY = "YOUR_SECRET_KEY"

S3_BUCKET = "YOUR_BUCKET"
S3_PREFIX = "ai_apt/vantage"  # 원하는 prefix

s3 = boto3.client(
    "s3",
    region_name=S3_REGION,
    endpoint_url=S3_ENDPOINT_URL,
    aws_access_key_id=S3_ACCESS_KEY,
    aws_secret_access_key=S3_SECRET_KEY,
)
print("S3 client ready")



# =========================================================
# CELL 4. S3 연결 테스트 + 유틸 함수
# =========================================================

def s3_head_test(bucket: str):
    # 버킷 권한 확인용 (권한 없으면 여기서 바로 에러)
    resp = s3.list_objects_v2(Bucket=bucket, MaxKeys=1)
    print("S3 access OK. sample keys:", [c.get("Key") for c in resp.get("Contents", [])])

def list_parquet_keys(bucket: str, prefix: str, limit: int = 5000):
    keys = []
    token = None
    while True:
        kwargs = dict(Bucket=bucket, Prefix=prefix, MaxKeys=1000)
        if token:
            kwargs["ContinuationToken"] = token
        resp = s3.list_objects_v2(**kwargs)
        for c in resp.get("Contents", []):
            k = c["Key"]
            if k.endswith(".parquet"):
                keys.append(k)
                if len(keys) >= limit:
                    return keys
        if not resp.get("IsTruncated"):
            break
        token = resp.get("NextContinuationToken")
    return keys

s3_head_test(S3_BUCKET)

# =========================================================
# CELL 5. VANTAGE station 마스터 CTE (PM/이벤트용 최소 컬럼)
# - chamber_ids 컬럼은 여기서 빼고 진행 (지금 에러 원인)
# =========================================================

MASTER_CTE = r"""
WITH team_station AS (
  SELECT DISTINCT
    m.STATION AS station,   -- 예: IMRB301-A
    m.ch_main AS ch_main,   -- 예: IMRB301 (main)
    m.area    AS area
  FROM fab.m_tpss_station_master m
  WHERE SUBSTR(m.room, -1) = '5'
    AND (
          m.STATION_NAME = 'VANTAGE-PLUS'
       OR m.STATION_NAME = 'VANTAGE_PLUS'
       OR m.STATION_NAME = 'VANTAGE'
        )
)
"""
print(MASTER_CTE)




# =========================================================
# CELL 6. PM 세션 생성 (0 row 해결 버전)
# - eqp_status_change_time 형식: 'yyyyMMdd HHmmss' (예: 20240407 155853)
# - CAST(... AS TIMESTAMP) 대신 unix_timestamp(string, format)으로 파싱
# =========================================================

def build_pm_sql(start_date, end_date, master_cte):
    # eqp_status_change_time 포맷에 맞춰 start/end도 같은 문자열로 생성
    start_str = start_date.strftime("%Y%m%d") + " 000000"
    end_str   = end_date.strftime("%Y%m%d")   + " 235959"

    sql = """
{MASTER_CTE}
, h AS (
  SELECT
    trim(upper(eqp_id)) AS station,
    eqp_status,

    -- ✅ 문자열 시간('yyyyMMdd HHmmss')을 epoch(초)로 파싱
    unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss') AS t_ep,

    LEAD(eqp_status, 1) OVER (
      PARTITION BY trim(upper(eqp_id))
      ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
    ) AS s1,

    LEAD(unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss'), 1) OVER (
      PARTITION BY trim(upper(eqp_id))
      ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
    ) AS t1_ep,

    LEAD(eqp_status, 2) OVER (
      PARTITION BY trim(upper(eqp_id))
      ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
    ) AS s2,

    LEAD(unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss'), 2) OVER (
      PARTITION BY trim(upper(eqp_id))
      ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
    ) AS t2_ep

  FROM mos_kh_smi.smimes_mi_eqp_hist
  WHERE trim(upper(eqp_id)) IN (SELECT trim(upper(station)) FROM team_station)
    AND eqp_id LIKE '%-%'
    AND unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss') BETWEEN
          unix_timestamp('{START_STR}', 'yyyyMMdd HHmmss')
      AND unix_timestamp('{END_STR}',   'yyyyMMdd HHmmss')
),
pm AS (
  SELECT
    station,

    -- 보기용 TIMESTAMP (epoch -> timestamp)
    CAST(from_unixtime(t_ep)  AS TIMESTAMP) AS pm_start_time,
    CAST(from_unixtime(t2_ep) AS TIMESTAMP) AS pm_end_time,

    CAST(t2_ep - t_ep AS BIGINT) AS dur_sec
  FROM h
  WHERE eqp_status = 'PM'
    AND s1 = 'LOCAL'
    AND s2 IN ('IDLE', 'RUN')
    AND t2_ep IS NOT NULL
),
pm2 AS (
  SELECT
    station,
    pm_start_time,
    pm_end_time,
    dur_sec,
    CONCAT(
      LPAD(CAST(FLOOR(dur_sec/3600) AS STRING), 2, '0'), ':',
      LPAD(CAST(FLOOR((dur_sec%3600)/60) AS STRING), 2, '0')
    ) AS dur_hhmm,
    CONCAT(station,'|',CAST(pm_start_time AS STRING)) AS pm_session_id
  FROM pm
  WHERE dur_sec BETWEEN 4*3600 AND 10*3600
)
SELECT *
FROM pm2
ORDER BY pm_start_time DESC
""".format(
        MASTER_CTE=master_cte,
        START_STR=start_str,
        END_STR=end_str
    )

    return sql


pm_sql = build_pm_sql(START_DATE, END_DATE, MASTER_CTE)
pm = getData(pm_sql)

print("pm rows:", len(pm))
pm.head(20)



# =========================================================
# CELL 7. RS EVENT 생성 (PM 구간 매칭, epoch 기준 통일)
# =========================================================

def build_rs_event_sql(start_date, end_date, master_cte):
    start_str = start_date.strftime("%Y-%m-%d") + " 00:00:00"
    end_str   = end_date.strftime("%Y-%m-%d")   + " 23:59:59"

    sql = """
{MASTER_CTE}
, rs_raw AS (
  SELECT
    trim(upper(prc_eqp_id)) || '-' || trim(upper(chamber_ids)) AS station,
    container_id,
    npw_wafer_id,
    prc_slot_id,
    prc_ppid,
    unix_timestamp(prc_tkin_time) AS rs_ep
  FROM fab.m_fab_npw_met
  WHERE item_id = 'RS1'
    AND prc_tkin_time BETWEEN
        CAST('{START_STR}' AS TIMESTAMP)
        AND CAST('{END_STR}' AS TIMESTAMP)
),
rs_event AS (
  SELECT
    r.station,
    r.container_id,
    r.npw_wafer_id,
    r.prc_slot_id,
    r.prc_ppid,
    CAST(from_unixtime(r.rs_ep) AS TIMESTAMP) AS rs_time,
    r.rs_ep,
    p.pm_session_id,
    p.pm_start_time,
    p.pm_end_time,
    ROW_NUMBER() OVER (
      PARTITION BY p.pm_session_id, r.station, r.prc_ppid
      ORDER BY r.rs_ep
    ) AS test_seq
  FROM rs_raw r
  JOIN (
        {MASTER_CTE}
        , h AS (
            SELECT
              trim(upper(eqp_id)) AS station,
              eqp_status,
              unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss') AS t_ep,
              LEAD(eqp_status,1) OVER (
                  PARTITION BY trim(upper(eqp_id))
                  ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
              ) AS s1,
              LEAD(unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss'),2) OVER (
                  PARTITION BY trim(upper(eqp_id))
                  ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
              ) AS t2_ep
            FROM mos_kh_smi.smimes_mi_eqp_hist
            WHERE trim(upper(eqp_id)) IN (SELECT trim(upper(station)) FROM team_station)
              AND eqp_id LIKE '%-%'
        )
        SELECT
            station,
            CAST(from_unixtime(t_ep) AS TIMESTAMP) AS pm_start_time,
            CAST(from_unixtime(t2_ep) AS TIMESTAMP) AS pm_end_time,
            CONCAT(station,'|',CAST(from_unixtime(t_ep) AS STRING)) AS pm_session_id,
            t_ep,
            t2_ep
        FROM h
        WHERE eqp_status='PM'
          AND s1='LOCAL'
          AND t2_ep IS NOT NULL
      ) p
    ON r.station = p.station
   AND r.rs_ep BETWEEN p.t_ep AND p.t2_ep
)
SELECT *
FROM rs_event
ORDER BY rs_time DESC
""".format(
        MASTER_CTE=master_cte,
        START_STR=start_str,
        END_STR=end_str
    )

    return sql


rs_sql = build_rs_event_sql(START_DATE, END_DATE, MASTER_CTE)
rs_event = getData(rs_sql)

print("rs_event rows:", len(rs_event))
rs_event.head(20)


# =========================================================
# CELL 8. events 생성 (RS 이벤트 + DCOP tempoffset 피벗)
# 목적:
# - rs_event(=PM 세션 내 RS 테스트 이벤트 1행) 기준으로
#   DCOP 테이블에서 tempoffset(t1~t7)을 붙여서 events(학습 메타 테이블) 완성
#
# 중요한 전제:
# - DCOP의 item_id는 'A_T1_OFFSET' ~ 'A_T7_OFFSET' (A/B는 챔버)
# - station 형식은 rs_event와 동일하게: "MAIN-CH" (예: IMRB301-A)
# - 시간은 epoch로 통일해서 조인 정확도를 높임
#
# 결과:
# - events: 1행 = (pm_session_id, station, rs_time, recipe, test_seq, line(area), t1~t7)
# - t1~t7이 하나라도 NULL이면 제거(사용자님 요청)
# =========================================================

def build_events_sql(start_date, end_date, master_cte, only_ppid=None):
    start_ts = start_date.strftime("%Y-%m-%d") + " 00:00:00"
    end_ts   = end_date.strftime("%Y-%m-%d")   + " 23:59:59"

    ppid_filter = ""
    if only_ppid:
        ppid_filter = " AND r.prc_ppid = '{PPID}' ".format(PPID=only_ppid.replace("'", "''"))

    sql = """
{MASTER_CTE}

-- 1) rs_event를 다시 SQL에서 생성 (CELL7과 동일 개념)
, pm AS (
  SELECT
    station,
    t_ep,
    t2_ep,
    CAST(from_unixtime(t_ep)  AS TIMESTAMP) AS pm_start_time,
    CAST(from_unixtime(t2_ep) AS TIMESTAMP) AS pm_end_time,
    CONCAT(station,'|',CAST(from_unixtime(t_ep) AS STRING)) AS pm_session_id
  FROM (
    SELECT
      trim(upper(eqp_id)) AS station,
      eqp_status,
      unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss') AS t_ep,
      LEAD(eqp_status, 1) OVER (
        PARTITION BY trim(upper(eqp_id))
        ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
      ) AS s1,
      LEAD(eqp_status, 2) OVER (
        PARTITION BY trim(upper(eqp_id))
        ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
      ) AS s2,
      LEAD(unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss'), 2) OVER (
        PARTITION BY trim(upper(eqp_id))
        ORDER BY unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss')
      ) AS t2_ep
    FROM mos_kh_smi.smimes_mi_eqp_hist
    WHERE trim(upper(eqp_id)) IN (SELECT trim(upper(station)) FROM team_station)
      AND eqp_id LIKE '%-%'
      AND unix_timestamp(eqp_status_change_time, 'yyyyMMdd HHmmss') BETWEEN
            unix_timestamp('{PM_START_STR}', 'yyyyMMdd HHmmss')
        AND unix_timestamp('{PM_END_STR}',   'yyyyMMdd HHmmss')
  ) x
  WHERE eqp_status='PM' AND s1='LOCAL' AND s2 IN ('IDLE','RUN') AND t2_ep IS NOT NULL
),
pm2 AS (
  SELECT
    station, t_ep, t2_ep, pm_start_time, pm_end_time, pm_session_id,
    CAST(t2_ep - t_ep AS BIGINT) AS dur_sec
  FROM pm
  WHERE (t2_ep - t_ep) BETWEEN 4*3600 AND 10*3600
),
rs_raw_event AS (
  SELECT DISTINCT
    trim(upper(prc_eqp_id)) || '-' || trim(upper(chamber_ids)) AS station,
    container_id,
    npw_wafer_id,
    prc_slot_id,
    prc_ppid,
    unix_timestamp(prc_tkin_time) AS rs_ep
  FROM fab.m_fab_npw_met
  WHERE item_id='RS1'
    AND prc_tkin_time BETWEEN CAST('{RS_START_TS}' AS TIMESTAMP) AND CAST('{RS_END_TS}' AS TIMESTAMP)
),
rs_event AS (
  SELECT
    r.station,
    p.pm_session_id,
    p.pm_start_time,
    p.pm_end_time,
    r.container_id,
    r.npw_wafer_id,
    r.prc_slot_id,
    CAST(from_unixtime(r.rs_ep) AS TIMESTAMP) AS rs_time,
    r.rs_ep,
    r.prc_ppid,
    -- 같은 rs_time + 같은 recipe는 같은 회차로 묶기: DENSE_RANK 권장
    DENSE_RANK() OVER (
      PARTITION BY p.pm_session_id, r.station, r.prc_ppid
      ORDER BY r.rs_ep
    ) AS test_seq
  FROM rs_raw_event r
  JOIN pm2 p
    ON r.station = p.station
   AND r.rs_ep BETWEEN p.t_ep AND p.t2_ep
  WHERE 1=1 {PPID_FILTER}
),

-- 2) DCOP raw: station, tk_ep(=prc_tkin_time), item_id, value
dcop_raw AS (
  SELECT
    trim(upper(prc_eqp_id)) || '-' || trim(upper(chamber_ids)) AS station,
    container_id,
    npw_wafer_id,
    prc_slot_id,
    unix_timestamp(prc_tkin_time) AS tk_ep,
    item_id,
    value
  FROM fab.m_fab_npw_dcop
  WHERE prc_tkin_time BETWEEN CAST('{RS_START_TS}' AS TIMESTAMP) AND CAST('{RS_END_TS}' AS TIMESTAMP)
),

-- 3) rs_event 키로 DCOP를 붙여 pivot(t1~t7)
dcop_pivot AS (
  SELECT
    r.pm_session_id,
    r.station,
    r.container_id,
    r.npw_wafer_id,
    r.prc_slot_id,
    r.rs_ep,

    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T1_OFFSET') THEN d.value END) AS t1,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T2_OFFSET') THEN d.value END) AS t2,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T3_OFFSET') THEN d.value END) AS t3,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T4_OFFSET') THEN d.value END) AS t4,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T5_OFFSET') THEN d.value END) AS t5,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T6_OFFSET') THEN d.value END) AS t6,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T7_OFFSET') THEN d.value END) AS t7

  FROM rs_event r
  LEFT JOIN dcop_raw d
    ON d.station      = r.station
   AND d.container_id = r.container_id
   AND d.npw_wafer_id = r.npw_wafer_id
   AND d.prc_slot_id  = r.prc_slot_id
   AND d.tk_ep        = r.rs_ep
  GROUP BY
    r.pm_session_id, r.station, r.container_id, r.npw_wafer_id, r.prc_slot_id, r.rs_ep
),

-- 4) 최종 events: line(area)도 붙임 (마스터에서)
final AS (
  SELECT
    r.pm_session_id,
    r.pm_start_time,
    r.pm_end_time,
    r.station,
    ts.area AS area,  -- 라인 정보
    r.container_id,
    r.npw_wafer_id,
    r.prc_slot_id,
    r.rs_time,
    r.prc_ppid,
    r.test_seq,
    p.t1, p.t2, p.t3, p.t4, p.t5, p.t6, p.t7
  FROM rs_event r
  LEFT JOIN team_station ts
    ON trim(upper(ts.station)) = trim(upper(r.station))
  LEFT JOIN dcop_pivot p
    ON p.pm_session_id = r.pm_session_id
   AND p.station = r.station
   AND p.container_id = r.container_id
   AND p.npw_wafer_id = r.npw_wafer_id
   AND p.prc_slot_id  = r.prc_slot_id
   AND p.rs_ep        = r.rs_ep
)

SELECT *
FROM final
WHERE t1 IS NOT NULL AND t2 IS NOT NULL AND t3 IS NOT NULL
  AND t4 IS NOT NULL AND t5 IS NOT NULL AND t6 IS NOT NULL AND t7 IS NOT NULL
ORDER BY rs_time DESC
""".format(
        MASTER_CTE=master_cte,
        PM_START_STR=start_date.strftime("%Y%m%d") + " 000000",
        PM_END_STR=end_date.strftime("%Y%m%d") + " 235959",
        RS_START_TS=start_ts,
        RS_END_TS=end_ts,
        PPID_FILTER=ppid_filter
    )

    return sql


events_sql = build_events_sql(START_DATE, END_DATE, MASTER_CTE, ONLY_PPID)
events = getData(events_sql)

print("events rows:", len(events))
events.head(50)


# =========================================================
# CELL 9. rs_long_v2 생성 및 S3 적재
#
# 목적
# - events(정답 키) 기준으로 RS1 포인트 데이터를 "long 형태"로 추출합니다.
# - wide로 펼치지 않고(subitem_id, value 형태 유지) → 메모리 폭발 방지
# - dt 파티션(= pm_start_time 날짜)별로 S3에 parquet 저장합니다.
#
# 핵심 포인트
# - JOIN 키는 사용자님이 확정한 "정확 매칭" 방식 사용:
#   station + container_id + npw_wafer_id + prc_slot_id + rs_time
# - station 형식 통일: "MAIN-CH" (예: IMRB301-A)
#   -> npw_met에서는 concat(prc_eqp_id,'-',chamber_ids) 로 생성
#
# 이번 수정사항(중요)
# - Impala에서 '||' 연산이 AND 조건과 섞이면 STRING||BOOLEAN 타입 오류가 날 수 있어
#   station 생성은 concat()로만 처리합니다.
# =========================================================

import pyarrow as pa
import pyarrow.parquet as pq
import io

def upload_parquet_df(df: pd.DataFrame, bucket: str, key: str):
    """pandas DataFrame을 parquet(snappy)로 S3 업로드"""
    buf = io.BytesIO()
    table = pa.Table.from_pandas(df, preserve_index=False)
    pq.write_table(table, buf, compression="snappy")
    buf.seek(0)
    s3.upload_fileobj(buf, bucket, key)
    print(f"uploaded: s3://{bucket}/{key} rows={len(df)}")


def build_keys_union_sql(ev_dt: pd.DataFrame) -> str:
    """
    events(특정 dt)에 있는 이벤트 키들을 Impala에서 사용할 수 있도록
    keys CTE (UNION ALL)로 변환합니다.

    keys 컬럼:
    - station, rs_time, container_id, npw_wafer_id, prc_slot_id
    - pm_session_id, prc_ppid, test_seq
    """
    rows = []
    for r in ev_dt.itertuples(index=False):
        station = str(r.station).replace("'", "''")
        rs_time = pd.to_datetime(r.rs_time).strftime("%Y-%m-%d %H:%M:%S")
        container = str(r.container_id).replace("'", "''")
        wafer = str(r.npw_wafer_id).replace("'", "''")
        slot = str(r.prc_slot_id).replace("'", "''")  # 문자열로 통일
        pm_session_id = str(r.pm_session_id).replace("'", "''")
        ppid = str(r.prc_ppid).replace("'", "''")
        test_seq = int(r.test_seq)

        rows.append(
            "SELECT "
            f"'{station}' AS station, "
            f"CAST('{rs_time}' AS TIMESTAMP) AS rs_time, "
            f"'{container}' AS container_id, "
            f"'{wafer}' AS npw_wafer_id, "
            f"'{slot}' AS prc_slot_id, "
            f"'{pm_session_id}' AS pm_session_id, "
            f"'{ppid}' AS prc_ppid, "
            f"{test_seq} AS test_seq"
        )

    return "\nUNION ALL\n".join(rows)


def build_rs_long_sql_from_events(ev_dt: pd.DataFrame) -> str:
    """
    dt 단위 events 키들을 기준으로 fab.m_fab_npw_met에서 RS1 포인트(long)를 뽑는 SQL을 만듭니다.
    """
    keys_sql = build_keys_union_sql(ev_dt)

    sql = """
WITH keys AS (
{KEYS_SQL}
)
SELECT
  k.station,
  k.pm_session_id,
  k.prc_ppid,
  k.test_seq,
  k.rs_time,
  k.container_id,
  k.npw_wafer_id,
  k.prc_slot_id,
  m.subitem_id,
  m.value
FROM fab.m_fab_npw_met m
JOIN keys k
  ON concat(trim(upper(m.prc_eqp_id)),'-',trim(upper(m.chamber_ids))) = k.station
 AND CAST(m.prc_tkin_time AS TIMESTAMP) = k.rs_time
 AND m.container_id = k.container_id
 AND m.npw_wafer_id = k.npw_wafer_id
 AND CAST(m.prc_slot_id AS STRING) = k.prc_slot_id
WHERE m.item_id = 'RS1'
  AND m.subitem_id RLIKE '^S[0-9]+$'
""".format(KEYS_SQL=keys_sql)

    return sql


# --- dt 파티션 생성 (pm_start_time 날짜 기준) ---
events = events.copy()
events["pm_start_time"] = pd.to_datetime(events["pm_start_time"])
events["dt"] = events["pm_start_time"].dt.strftime("%Y-%m-%d")

dt_list = sorted(events["dt"].unique().tolist())
print("dt_list:", dt_list, "count:", len(dt_list))


# --- dt 별로 rs_long 추출 & S3 저장 ---
for i, dt in enumerate(dt_list, 1):
    ev_dt = events[events["dt"] == dt].copy()
    if len(ev_dt) == 0:
        continue

    rs_long_sql = build_rs_long_sql_from_events(ev_dt)
    rs_long_dt = getData(rs_long_sql)

    # 편의상 dt 컬럼 추가(나중에 pandas에서 필터할 때 유용)
    rs_long_dt["dt"] = dt

    out_key = f"{S3_PREFIX}/rs_long_v2/dt={dt}/part-0.parquet"
    upload_parquet_df(rs_long_dt, S3_BUCKET, out_key)

    print(f"[{i}/{len(dt_list)}] done dt={dt}, rs_long rows={len(rs_long_dt)}")




# =========================================================
# CELL 10. 검증: rs_long_v2(dt)를 S3에서 읽어 포인트 개수 분포 확인
#
# 목적
# - 이벤트(= test 1회)당 subitem_id(S숫자) 개수가 몇 개인지 확인
# - 기대값: 49 / 81 / 121 / 151 (라인/레시피별 RS 포인트 셋)
# - 0이 섞이면: join 누락/키 불일치/필터 문제 가능성이 큼
# =========================================================

import io
import pyarrow.parquet as pq

def load_rs_long_v2_dt_from_s3(dt: str) -> pd.DataFrame:
    key = f"{S3_PREFIX}/rs_long_v2/dt={dt}/part-0.parquet"
    obj = s3.get_object(Bucket=S3_BUCKET, Key=key)
    buf = io.BytesIO(obj["Body"].read())
    df = pq.read_table(buf).to_pandas()
    df["dt"] = dt
    return df

check_dt = dt_list[0]
rs_check = load_rs_long_v2_dt_from_s3(check_dt)

key_cols = [
    "pm_session_id","prc_ppid","test_seq","station",
    "container_id","npw_wafer_id","prc_slot_id","rs_time"
]

vc = (rs_check.groupby(key_cols, observed=True)["subitem_id"]
      .nunique()
      .value_counts()
      .sort_index())

print("check_dt:", check_dt)
print("point-count distribution:")
print(vc)

rs_check.head(30)
