# =========================================================
# CELL 1. 환경/라이브러리 준비
# - 데이터 조회(getData), pandas 처리, S3 업로드(boto3), parquet 저장(pyarrow)
# =========================================================

from bigdataquery import getData
import pandas as pd
import numpy as np
import boto3
import io
import re
from datetime import datetime, timedelta, date

import pyarrow as pa
import pyarrow.parquet as pq

pd.set_option("display.max_columns", 200)
pd.set_option("display.width", 200)



# =========================================================
# CELL 2. 기본 파라미터 설정
# - 개발 단계에서는 기간을 짧게(10~30일)로 검증
# - 운영/1년치는 나중에 동일 코드로 확장 가능
# =========================================================

# 조회 기간 (Impala TIMESTAMP 기반)
END_DATE = date.today() - timedelta(days=1)          # 어제
START_DATE = END_DATE - timedelta(days=30)          # 최근 30일 (검증용)
# START_DATE = END_DATE - timedelta(days=365)       # 1년치로 갈 때

# 특정 RS 레시피만 보고 싶으면 넣기 (없으면 None)
ONLY_PPID = None
# ONLY_PPID = "TT_RA-108030"

print("START_DATE:", START_DATE, "END_DATE:", END_DATE, "ONLY_PPID:", ONLY_PPID)




# =========================================================
# CELL 3. S3 접속 설정 (endpoint 포함)
# - 회사 환경에서는 endpoint_url이 필수인 경우가 많음
# - 아래 값은 사용자 환경에 맞게 채우세요
# =========================================================

S3_ENDPOINT_URL = "https://YOUR_S3_ENDPOINT"   # 예: https://s3.company.com
S3_REGION = "ap-northeast-2"                   # 보통 서울
S3_ACCESS_KEY = "YOUR_ACCESS_KEY"
S3_SECRET_KEY = "YOUR_SECRET_KEY"

S3_BUCKET = "YOUR_BUCKET"
S3_PREFIX = "ai_apt/vantage"  # 원하는 prefix

s3 = boto3.client(
    "s3",
    region_name=S3_REGION,
    endpoint_url=S3_ENDPOINT_URL,
    aws_access_key_id=S3_ACCESS_KEY,
    aws_secret_access_key=S3_SECRET_KEY,
)
print("S3 client ready")



# =========================================================
# CELL 4. S3 연결 테스트 + 유틸 함수
# =========================================================

def s3_head_test(bucket: str):
    # 버킷 권한 확인용 (권한 없으면 여기서 바로 에러)
    resp = s3.list_objects_v2(Bucket=bucket, MaxKeys=1)
    print("S3 access OK. sample keys:", [c.get("Key") for c in resp.get("Contents", [])])

def list_parquet_keys(bucket: str, prefix: str, limit: int = 5000):
    keys = []
    token = None
    while True:
        kwargs = dict(Bucket=bucket, Prefix=prefix, MaxKeys=1000)
        if token:
            kwargs["ContinuationToken"] = token
        resp = s3.list_objects_v2(**kwargs)
        for c in resp.get("Contents", []):
            k = c["Key"]
            if k.endswith(".parquet"):
                keys.append(k)
                if len(keys) >= limit:
                    return keys
        if not resp.get("IsTruncated"):
            break
        token = resp.get("NextContinuationToken")
    return keys

s3_head_test(S3_BUCKET)




# =========================================================
# CELL 5. VANTAGE station 마스터 CTE
# - 앞으로 모든 데이터는 이 station 목록으로 "우리 팀 설비만" 제한
# =========================================================

MASTER_CTE = r"""
WITH team_station AS (
  SELECT DISTINCT
    m.STATION      AS station,   -- 예: IMRB301-A (main+ch 형태)
    m.ch_main      AS ch_main,   -- 예: IMRB301 (main만)
    m.chamber_ids  AS chamber_ids, -- 예: A (또는 [A] 형태일 수도 있으니 아래에서 처리)
    m.area         AS area
  FROM fab.m_tpss_station_master m
  WHERE SUBSTR(m.room, -1) = '5'
    AND (
          m.STATION_NAME = 'VANTAGE-PLUS'
       OR m.STATION_NAME = 'VANTAGE_PLUS'
       OR m.STATION_NAME = 'VANTAGE'
        )
)
"""
print(MASTER_CTE[:400], "...")


# =========================================================
# CELL 6. PM 세션 테이블(pm) 생성 SQL (에러 수정 버전)
# - Impala에서 TIMESTAMP '...' 리터럴이 파싱 에러 나는 환경 대응
# - unix_timestamp()가 TIMESTAMP를 직접 못 받는 환경 대응 (CAST -> STRING)
# =========================================================

def build_pm_sql(start_date: date, end_date: date) -> str:
    start_ts = f"{start_date.strftime('%Y-%m-%d')} 00:00:00"
    end_ts   = f"{end_date.strftime('%Y-%m-%d')} 23:59:59"

    sql = f"""
{MASTER_CTE}
, h AS (
  SELECT
    eqp_id AS station,
    line_id,
    origin_line_id,
    eqp_status,
    CAST(eqp_status_change_time AS TIMESTAMP) AS t,

    LEAD(eqp_status, 1) OVER (
      PARTITION BY eqp_id
      ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)
    ) AS s1,
    LEAD(CAST(eqp_status_change_time AS TIMESTAMP), 1) OVER (
      PARTITION BY eqp_id
      ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)
    ) AS t1,

    LEAD(eqp_status, 2) OVER (
      PARTITION BY eqp_id
      ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)
    ) AS s2,
    LEAD(CAST(eqp_status_change_time AS TIMESTAMP), 2) OVER (
      PARTITION BY eqp_id
      ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)
    ) AS t2

  FROM mos_kh_smi.smimes_mi_eqp_hist
  WHERE eqp_id IN (SELECT station FROM team_station)
    AND eqp_id LIKE '%-%'
    AND CAST(eqp_status_change_time AS TIMESTAMP) BETWEEN
          CAST('{start_ts}' AS TIMESTAMP)
      AND CAST('{end_ts}'   AS TIMESTAMP)
),
pm AS (
  SELECT
    station,
    t  AS pm_start_time,
    t2 AS pm_end_time,

    -- ✅ TIMESTAMP를 unix_timestamp에 직접 넣지 않고 STRING으로 캐스팅해서 계산
    CAST(
      unix_timestamp(CAST(t2 AS STRING)) - unix_timestamp(CAST(t AS STRING))
      AS BIGINT
    ) AS dur_sec

  FROM h
  WHERE eqp_status = 'PM'
    AND s1 = 'LOCAL'
    AND s2 IN ('IDLE', 'RUN')
    AND t

# =========================================================
# CELL 7. RS 이벤트(rs_event) 생성
# - PM 기간 내에 수행된 RS1 결과를 이벤트 단위로 만들고(test_seq 부여)
# =========================================================

def build_rs_event_sql(start_date: date, end_date: date, only_ppid: str | None) -> str:
    start_ts = f"{start_date.strftime('%Y-%m-%d')} 00:00:00"
    end_ts   = f"{end_date.strftime('%Y-%m-%d')} 23:59:59"

    ppid_filter = ""
    if only_ppid:
        ppid_filter = f" AND m.prc_ppid = '{only_ppid}' "

    sql = f"""
{MASTER_CTE}
, pm AS (
  -- CELL6과 동일 로직(재사용): PM 세션 생성
  SELECT
    station,
    pm_start_time,
    pm_end_time,
    CONCAT(station,'|',CAST(pm_start_time AS STRING)) AS pm_session_id
  FROM (
    SELECT
      station,
      t  AS pm_start_time,
      t2 AS pm_end_time,
      CAST(unix_timestamp(t2) - unix_timestamp(t) AS BIGINT) AS dur_sec
    FROM (
      SELECT
        eqp_id AS station,
        eqp_status,
        CAST(eqp_status_change_time AS TIMESTAMP) AS t,
        LEAD(eqp_status, 1) OVER (PARTITION BY eqp_id ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)) AS s1,
        LEAD(CAST(eqp_status_change_time AS TIMESTAMP), 2) OVER (PARTITION BY eqp_id ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)) AS t2,
        LEAD(eqp_status, 2) OVER (PARTITION BY eqp_id ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)) AS s2
      FROM mos_kh_smi.smimes_mi_eqp_hist
      WHERE eqp_id IN (SELECT station FROM team_station)
        AND eqp_id LIKE '%-%'
        AND CAST(eqp_status_change_time AS TIMESTAMP) BETWEEN TIMESTAMP '{start_ts}' AND TIMESTAMP '{end_ts}'
    ) x
    WHERE eqp_status='PM' AND s1='LOCAL' AND s2 IN ('IDLE','RUN') AND t2 IS NOT NULL
  ) y
  WHERE dur_sec BETWEEN 4*3600 AND 10*3600
),
rs_raw AS (
  SELECT
    CONCAT(m.prc_eqp_id,'-',m.chamber_ids) AS station,
    m.container_id,
    m.npw_wafer_id,
    m.prc_slot_id,
    CAST(m.prc_tkin_time AS TIMESTAMP) AS rs_time,
    m.prc_ppid,
    m.subitem_id,
    m.value
  FROM fab.m_fab_npw_met m
  WHERE CAST(m.prc_tkin_time AS TIMESTAMP) BETWEEN TIMESTAMP '{start_ts}' AND TIMESTAMP '{end_ts}'
    AND m.item_id = 'RS1'
    AND m.subitem_id RLIKE '^S[0-9]+$'       -- AVG/STD 등 제거, S숫자만
    {ppid_filter}
),
rs_in_pm AS (
  SELECT
    p.pm_session_id,
    p.pm_start_time,
    p.pm_end_time,
    p.station,
    r.container_id,
    r.npw_wafer_id,
    r.prc_slot_id,
    r.rs_time,
    r.prc_ppid
  FROM pm p
  JOIN (
    -- 이벤트 단위(한 번의 RS test): 동일 키에서 중복 제거
    SELECT DISTINCT
      station, container_id, npw_wafer_id, prc_slot_id, rs_time, prc_ppid
    FROM rs_raw
  ) r
    ON r.station = p.station
   AND r.rs_time BETWEEN p.pm_start_time AND p.pm_end_time
),
rs_event AS (
  SELECT
    station,
    pm_session_id,
    pm_start_time,
    pm_end_time,
    container_id,
    npw_wafer_id,
    prc_slot_id,
    rs_time,
    prc_ppid,
    -- 같은 pm_session_id + station + prc_ppid 내에서 rs_time 순서로 test_seq
    DENSE_RANK() OVER (
      PARTITION BY pm_session_id, station, prc_ppid
      ORDER BY rs_time
    ) AS test_seq
  FROM rs_in_pm
)
SELECT * FROM rs_event
ORDER BY rs_time DESC
"""
    return sql

rs_event_sql = build_rs_event_sql(START_DATE, END_DATE, ONLY_PPID)
rs_event = getData(rs_event_sql)

print("rs_event rows:", len(rs_event))
rs_event.head(50)




# =========================================================
# CELL 8. events 생성 (RS 이벤트 + DCOP pivot + 라인(area) 부여)
# - 결과: 이벤트 1행당 (메타 + t1~t7) 가 완성됨
# - t1~t7이 하나라도 NULL이면 제거 (사용자님 요청)
# =========================================================

def build_events_sql(start_date: date, end_date: date, only_ppid: str | None) -> str:
    start_ts = f"{start_date.strftime('%Y-%m-%d')} 00:00:00"
    end_ts   = f"{end_date.strftime('%Y-%m-%d')} 23:59:59"

    ppid_filter = ""
    if only_ppid:
        ppid_filter = f" AND r.prc_ppid = '{only_ppid}' "

    sql = f"""
{MASTER_CTE}
, pm AS (
  SELECT
    station,
    pm_start_time,
    pm_end_time,
    CONCAT(station,'|',CAST(pm_start_time AS STRING)) AS pm_session_id
  FROM (
    SELECT
      station,
      t  AS pm_start_time,
      t2 AS pm_end_time,
      CAST(unix_timestamp(t2) - unix_timestamp(t) AS BIGINT) AS dur_sec
    FROM (
      SELECT
        eqp_id AS station,
        eqp_status,
        CAST(eqp_status_change_time AS TIMESTAMP) AS t,
        LEAD(eqp_status, 1) OVER (PARTITION BY eqp_id ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)) AS s1,
        LEAD(CAST(eqp_status_change_time AS TIMESTAMP), 2) OVER (PARTITION BY eqp_id ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)) AS t2,
        LEAD(eqp_status, 2) OVER (PARTITION BY eqp_id ORDER BY CAST(eqp_status_change_time AS TIMESTAMP)) AS s2
      FROM mos_kh_smi.smimes_mi_eqp_hist
      WHERE eqp_id IN (SELECT station FROM team_station)
        AND eqp_id LIKE '%-%'
        AND CAST(eqp_status_change_time AS TIMESTAMP) BETWEEN TIMESTAMP '{start_ts}' AND TIMESTAMP '{end_ts}'
    ) x
    WHERE eqp_status='PM' AND s1='LOCAL' AND s2 IN ('IDLE','RUN') AND t2 IS NOT NULL
  ) y
  WHERE dur_sec BETWEEN 4*3600 AND 10*3600
),
rs_raw_event AS (
  SELECT DISTINCT
    CONCAT(m.prc_eqp_id,'-',m.chamber_ids) AS station,
    m.container_id,
    m.npw_wafer_id,
    m.prc_slot_id,
    CAST(m.prc_tkin_time AS TIMESTAMP) AS rs_time,
    m.prc_ppid
  FROM fab.m_fab_npw_met m
  WHERE CAST(m.prc_tkin_time AS TIMESTAMP) BETWEEN TIMESTAMP '{start_ts}' AND TIMESTAMP '{end_ts}'
    AND m.item_id = 'RS1'
    AND m.subitem_id RLIKE '^S[0-9]+$'
),
rs_in_pm AS (
  SELECT
    p.pm_session_id,
    p.pm_start_time,
    p.pm_end_time,
    r.station,
    r.container_id,
    r.npw_wafer_id,
    r.prc_slot_id,
    r.rs_time,
    r.prc_ppid
  FROM pm p
  JOIN rs_raw_event r
    ON r.station = p.station
   AND r.rs_time BETWEEN p.pm_start_time AND p.pm_end_time
),
rs_event AS (
  SELECT
    station,
    pm_session_id,
    pm_start_time,
    pm_end_time,
    container_id,
    npw_wafer_id,
    prc_slot_id,
    rs_time,
    prc_ppid,
    DENSE_RANK() OVER (
      PARTITION BY pm_session_id, station, prc_ppid
      ORDER BY rs_time
    ) AS test_seq
  FROM rs_in_pm
  WHERE 1=1 {ppid_filter}
),
dcop_raw AS (
  SELECT
    CONCAT(d.prc_eqp_id,'-',d.chamber_ids) AS station,
    d.container_id,
    d.npw_wafer_id,
    d.prc_slot_id,
    CAST(d.prc_tkin_time AS TIMESTAMP) AS tk_time,
    d.item_id,
    d.value
  FROM fab.m_fab_npw_dcop d
  WHERE CAST(d.prc_tkin_time AS TIMESTAMP) BETWEEN TIMESTAMP '{start_ts}' AND TIMESTAMP '{end_ts}'
),
dcop_pivot AS (
  SELECT
    r.station,
    r.container_id,
    r.npw_wafer_id,
    r.prc_slot_id,
    r.rs_time,
    -- station의 챔버 문자: 'IMRB301-A' -> 'A'
    split_part(r.station,'-',2) AS ch,

    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T1_OFFSET') THEN d.value END) AS t1,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T2_OFFSET') THEN d.value END) AS t2,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T3_OFFSET') THEN d.value END) AS t3,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T4_OFFSET') THEN d.value END) AS t4,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T5_OFFSET') THEN d.value END) AS t5,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T6_OFFSET') THEN d.value END) AS t6,
    MAX(CASE WHEN d.item_id = concat(split_part(r.station,'-',2),'_T7_OFFSET') THEN d.value END) AS t7
  FROM rs_event r
  LEFT JOIN dcop_raw d
    ON d.station      = r.station
   AND d.container_id = r.container_id
   AND d.npw_wafer_id = r.npw_wafer_id
   AND d.prc_slot_id  = r.prc_slot_id
   AND d.tk_time      = r.rs_time
  GROUP BY
    r.station, r.container_id, r.npw_wafer_id, r.prc_slot_id, r.rs_time
),
final AS (
  SELECT
    r.pm_session_id,
    r.pm_start_time,
    r.pm_end_time,
    r.station,
    ts.area AS area,          -- 라인(사용자님: area가 라인 컬럼)
    r.container_id,
    r.npw_wafer_id,
    r.prc_slot_id,
    r.rs_time,
    r.prc_ppid,
    r.test_seq,
    p.t1, p.t2, p.t3, p.t4, p.t5, p.t6, p.t7
  FROM rs_event r
  LEFT JOIN team_station ts
    ON ts.station = r.station
  LEFT JOIN dcop_pivot p
    ON p.station = r.station
   AND p.container_id = r.container_id
   AND p.npw_wafer_id = r.npw_wafer_id
   AND p.prc_slot_id  = r.prc_slot_id
   AND p.rs_time      = r.rs_time
)
SELECT *
FROM final
WHERE t1 IS NOT NULL AND t2 IS NOT NULL AND t3 IS NOT NULL
  AND t4 IS NOT NULL AND t5 IS NOT NULL AND t6 IS NOT NULL AND t7 IS NOT NULL
ORDER BY rs_time DESC
"""
    return sql

events_sql = build_events_sql(START_DATE, END_DATE, ONLY_PPID)
events = getData(events_sql)

print("events rows:", len(events))
events.head(100)




# =========================================================
# CELL 9. rs_long_v2 생성/적재
# - events(정답 키) 기준으로 RS1 포인트를 long으로 뽑아 dt 파티션으로 저장
# - 메모리 폭발 방지: dt 단위로만 처리
# =========================================================

def upload_parquet_df(df: pd.DataFrame, bucket: str, key: str):
    buf = io.BytesIO()
    table = pa.Table.from_pandas(df, preserve_index=False)
    pq.write_table(table, buf, compression="snappy")
    buf.seek(0)
    s3.upload_fileobj(buf, bucket, key)
    print(f"uploaded: s3://{bucket}/{key} rows={len(df)}")

def build_rs_long_sql_for_dt(dt: str) -> str:
    # dt는 'YYYY-MM-DD' (pm_start_time 기준)
    # 해당 dt에 속한 events만 keys로 만들어 RS를 join
    keys = events.copy()
    keys["pm_start_time"] = pd.to_datetime(keys["pm_start_time"])
    keys["rs_time"] = pd.to_datetime(keys["rs_time"])
    keys["prc_slot_id"] = keys["prc_slot_id"].astype(str)

    keys["dt"] = keys["pm_start_time"].dt.strftime("%Y-%m-%d")
    ev_dt = keys[keys["dt"] == dt].copy()

    if len(ev_dt) == 0:
        return None

    # Impala에 넣기 위해 keys를 UNION ALL로 만듦 (너무 길어지면 chunk로 나눠야 함)
    rows = []
    for r in ev_dt.itertuples(index=False):
        station = str(r.station).replace("'", "''")
        rs_time = pd.to_datetime(r.rs_time).strftime("%Y-%m-%d %H:%M:%S")
        container = str(r.container_id).replace("'", "''")
        wafer = str(r.npw_wafer_id).replace("'", "''")
        slot = str(r.prc_slot_id).replace("'", "''")
        pm_session_id = str(r.pm_session_id).replace("'", "''")
        ppid = str(r.prc_ppid).replace("'", "''")
        test_seq = int(r.test_seq)

        rows.append(
            "SELECT "
            f"'{station}' AS station, "
            f"CAST('{rs_time}' AS TIMESTAMP) AS rs_time, "
            f"'{container}' AS container_id, "
            f"'{wafer}' AS npw_wafer_id, "
            f"'{slot}' AS prc_slot_id, "
            f"'{pm_session_id}' AS pm_session_id, "
            f"'{ppid}' AS prc_ppid, "
            f"{test_seq} AS test_seq"
        )

    keys_sql = "\nUNION ALL\n".join(rows)

    sql = f"""
WITH keys AS (
{keys_sql}
)
SELECT
  k.station,
  k.pm_session_id,
  k.prc_ppid,
  k.test_seq,
  k.rs_time,
  k.container_id,
  k.npw_wafer_id,
  k.prc_slot_id,
  m.subitem_id,
  m.value
FROM fab.m_fab_npw_met m
JOIN keys k
  ON concat(m.prc_eqp_id,'-',m.chamber_ids) = k.station
 AND CAST(m.prc_tkin_time AS TIMESTAMP) = k.rs_time
 AND m.container_id = k.container_id
 AND m.npw_wafer_id = k.npw_wafer_id
 AND m.prc_slot_id  = k.prc_slot_id
WHERE m.item_id = 'RS1'
  AND m.subitem_id RLIKE '^S[0-9]+$'
"""
    return sql

# dt 리스트
events["pm_start_time"] = pd.to_datetime(events["pm_start_time"])
dt_list = sorted(events["pm_start_time"].dt.strftime("%Y-%m-%d").unique().tolist())
print("dt_list:", dt_list, "count:", len(dt_list))

for i, dt in enumerate(dt_list, 1):
    sql = build_rs_long_sql_for_dt(dt)
    if sql is None:
        continue
    rs_long_dt = getData(sql)
    key = f"{S3_PREFIX}/rs_long_v2/dt={dt}/part-0.parquet"
    upload_parquet_df(rs_long_dt, S3_BUCKET, key)
    print(f"[{i}/{len(dt_list)}] done dt={dt}")




# =========================================================
# CELL 10. 검증: dt 하나 로드해서 포인트 개수 분포 확인
# - groupby observed=True로 "가짜 0그룹" 방지
# =========================================================

def load_rs_long_v2_dt_from_s3(dt: str) -> pd.DataFrame:
    key = f"{S3_PREFIX}/rs_long_v2/dt={dt}/part-0.parquet"
    obj = s3.get_object(Bucket=S3_BUCKET, Key=key)
    buf = io.BytesIO(obj["Body"].read())
    df = pq.read_table(buf).to_pandas()
    return df

# 임의 dt 하나 선택
check_dt = dt_list[0]
rs_check = load_rs_long_v2_dt_from_s3(check_dt)

key_cols_fixed = ["pm_session_id","prc_ppid","test_seq","station","container_id","npw_wafer_id","prc_slot_id"]

vc = (rs_check.groupby(key_cols_fixed, observed=True)["subitem_id"]
      .nunique()
      .value_counts()
      .sort_index())

print("check_dt:", check_dt)
print(vc)
rs_check.head(20)
